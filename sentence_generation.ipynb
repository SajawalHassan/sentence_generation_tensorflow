{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23vf4_QK2BkT"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZEvn9Bzb-AB"
      },
      "outputs": [],
      "source": [
        "import os, zipfile, glob, json, string, shutil\n",
        "\n",
        "from google.colab.files import upload\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import tensorflow.keras.utils as ku\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SQZVjEr_2LWj"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D9HXaIxUjgQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt87wyylbJvA"
      },
      "source": [
        "## Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "e8l9-r5kbLLE",
        "outputId": "b56f45a9-03af-45a6-901c-7e080a9d172e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing kaggle\n",
            "Upload kaggle.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a171c1d-ae9d-4316-ad47-0aa4ff4d134e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7a171c1d-ae9d-4316-ad47-0aa4ff4d134e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Setting kaggle up...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing kaggle\")\n",
        "!pip install kaggle -q\n",
        "print(\"Upload kaggle.json\")\n",
        "upload()\n",
        "print(\"Setting kaggle up...\")\n",
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!rm -fr sample_data\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4IQXjZ9bpeH"
      },
      "source": [
        "## Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iurQEu2ubxHU"
      },
      "outputs": [],
      "source": [
        "data_name = \"data\"\n",
        "train_data = \"data/train\"\n",
        "test_data = \"data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y4QwjmiLb5dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8069f1-9b81-4b86-fd62-8af13253277e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading multiwoz-22.zip to /content\n",
            " 34% 5.00M/14.8M [00:00<00:00, 48.5MB/s]\n",
            "100% 14.8M/14.8M [00:00<00:00, 79.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(data_name):\n",
        "  !kaggle datasets download -d taejinwoo/multiwoz-22\n",
        "  with zipfile.ZipFile(\"multiwoz-22.zip\", \"r\") as zip_ref: zip_ref.extractall(\"./\")\n",
        "  os.remove(\"multiwoz-22.zip\")\n",
        "  os.rename(\"MultiWOZ_2.2\", data_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jBAuvy6cWxB"
      },
      "source": [
        "## Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7B_IIr-glT0K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "e0665b84-dbe4-4785-c2ee-8fa0f058fadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total num of rows 17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentences\n",
              "0  [I am looking for the Addenbrookes Hospital wi...\n",
              "1  [I am looking for something fun to do in the s...\n",
              "2  [i need a place to dine in the center thats ex...\n",
              "3  [I need a train to stansted airport that leave...\n",
              "4  [Hi, I'm looking for places to visit. Mainly i..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47d07a54-6156-4dc9-af6c-97c323d5eeae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[I am looking for the Addenbrookes Hospital wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[I am looking for something fun to do in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[i need a place to dine in the center thats ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[I need a train to stansted airport that leave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Hi, I'm looking for places to visit. Mainly i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47d07a54-6156-4dc9-af6c-97c323d5eeae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47d07a54-6156-4dc9-af6c-97c323d5eeae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47d07a54-6156-4dc9-af6c-97c323d5eeae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "sentences = []\n",
        "for i, filepath in enumerate(glob.glob(f\"{train_data}/*.json\")):\n",
        "  with open(filepath, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  utterances = []\n",
        "  for item in data:\n",
        "    for turn in item[\"turns\"]:\n",
        "      utterances.append(turn[\"utterance\"])\n",
        "\n",
        "  sentences.append(utterances)\n",
        "\n",
        "df_ = pd.DataFrame({\"sentences\": sentences})\n",
        "print(\"Total num of rows\", len(df_.index))\n",
        "df_.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VzBHvj71Whpw"
      },
      "outputs": [],
      "source": [
        "max_rows = 100\n",
        "all_sentences = []\n",
        "\n",
        "for i in range(len(df_.loc[:, \"sentences\"]) - 1):\n",
        "  sentences = df_.loc[i, \"sentences\"]\n",
        "\n",
        "  for sentence in sentences:\n",
        "    if len(all_sentences) + 1 > max_rows: break\n",
        "\n",
        "    all_sentences.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt\n",
        "\n",
        "corpus = [clean_text(x) for x in all_sentences]\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSRyU3d7oASs",
        "outputId": "0f73ce0a-8a86-44f1-ee6b-492e78b572ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i am looking for the addenbrookes hospital with hepatology department',\n",
              " 'the telephone number is 01223217712',\n",
              " 'thank you goodbye',\n",
              " 'have a wonderful day',\n",
              " 'im planning a trip to cambridge and need a place to dine can you find something that serves jamaican food in the centre',\n",
              " 'there are no jamaican restaurants in the centre would you like to try another area or another food type',\n",
              " 'are you sure it should be expensive',\n",
              " 'im sorry there doesnt seem to be a jamaican restaurant in centre would you like me to look for something else',\n",
              " 'i really want jamaican food can you check another area if you find one it should be expensive if not ill try thai in the centre',\n",
              " 'that should be bangkok city its address is 24 green street city centrecb23jx you need the phone number']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create n-gram sequences"
      ],
      "metadata": {
        "id": "6_Pz__cwuYJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def create_sequences(corpus):\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "  sequences = []\n",
        "  for sentence in corpus:\n",
        "    tok_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, total_words):\n",
        "      n_gram_seq = tok_sentence[:i+1]\n",
        "      sequences.append(n_gram_seq)\n",
        "\n",
        "  return sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = create_sequences(corpus)\n",
        "inp_sequences[:10]"
      ],
      "metadata": {
        "id": "ZDpXxJCkE93E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f990147-db89-4dcd-9652-54582a458038"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 52],\n",
              " [4, 52, 35],\n",
              " [4, 52, 35, 7],\n",
              " [4, 52, 35, 7, 2],\n",
              " [4, 52, 35, 7, 2, 171],\n",
              " [4, 52, 35, 7, 2, 171, 172],\n",
              " [4, 52, 35, 7, 2, 171, 172, 17],\n",
              " [4, 52, 35, 7, 2, 171, 172, 17, 173],\n",
              " [4, 52, 35, 7, 2, 171, 172, 17, 173, 174],\n",
              " [4, 52, 35, 7, 2, 171, 172, 17, 173, 174]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pad n-gram sequences"
      ],
      "metadata": {
        "id": "Mw01G08xpqNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequences_labels(sequences, pad_len):\n",
        "  padded_sequences = np.array(ku.pad_sequences(sequences, maxlen=pad_len, padding=\"pre\"))\n",
        "\n",
        "  inputs, labels = padded_sequences[:,:-1], padded_sequences[:,-1]\n",
        "  labels = ku.to_categorical(labels, num_classes=total_words)\n",
        "  return inputs, labels\n",
        "\n",
        "max_seq_len = max([len(seq) for seq in inp_sequences])\n",
        "inputs, labels = split_sequences_labels(inp_sequences, max_seq_len)"
      ],
      "metadata": {
        "id": "S0w8AFxNs8qf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "Azp0-fVv4dFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building model"
      ],
      "metadata": {
        "id": "U4yZNRTyKxpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "optim = tf.keras.optimizers.Adam()\n",
        "\n",
        "input_len = max_seq_len - 1\n",
        "model = Sequential()\n",
        "\n",
        "# Add Input Embedding Layer\n",
        "model.add(layers.Embedding(256, 30, input_length=input_len))\n",
        "\n",
        "# Add Dense Layers\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Add Hidden Layer 1 - LSTM Layer\n",
        "model.add(layers.LSTM(256))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss=loss, optimizer=optim)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWYBxliuwBXg",
        "outputId": "b795c66b-44fd-468f-cedb-be2edf8192ea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 30, 30)            7680      \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 30, 512)           15872     \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 30, 256)           131328    \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 30, 128)           32896     \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 30, 64)            8256      \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 30, 32)            2080      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 30, 16)            528       \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 30, 8)             136       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 30, 4)             36        \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 30, 8)             40        \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 30, 16)            144       \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 30, 32)            544       \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 30, 64)            2112      \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 30, 128)           8320      \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 30, 256)           33024     \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 30, 512)           131584    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 30, 512)           0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 351)               90207     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,252,243\n",
            "Trainable params: 1,252,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "VPs1iCiK0su0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='./training_checkpoints/ckpt_{epoch}',\n",
        "        save_weights_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True),\n",
        "]\n",
        "\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "history = model.fit(inputs, labels, epochs=epochs, batch_size=batch_size, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viwwYq0iYjN1",
        "outputId": "addf538e-e25e-4c8f-d0ed-e13c06bf42a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1094/1094 [==============================] - 41s 30ms/step - loss: 2.0892\n",
            "Epoch 2/200\n",
            "1094/1094 [==============================] - 18s 16ms/step - loss: 0.3179\n",
            "Epoch 3/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.2239\n",
            "Epoch 4/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.1833\n",
            "Epoch 5/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.1600\n",
            "Epoch 6/200\n",
            "1094/1094 [==============================] - 18s 16ms/step - loss: 0.1421\n",
            "Epoch 7/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.1298\n",
            "Epoch 8/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.1217\n",
            "Epoch 9/200\n",
            "1094/1094 [==============================] - 19s 17ms/step - loss: 0.1919\n",
            "Epoch 10/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.1229\n",
            "Epoch 11/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.1145\n",
            "Epoch 12/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.1014\n",
            "Epoch 13/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.1041\n",
            "Epoch 14/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.1958\n",
            "Epoch 15/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.1223\n",
            "Epoch 16/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.1005\n",
            "Epoch 17/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0888\n",
            "Epoch 18/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0794\n",
            "Epoch 19/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0738\n",
            "Epoch 20/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0715\n",
            "Epoch 21/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0628\n",
            "Epoch 22/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.0587\n",
            "Epoch 23/200\n",
            "1094/1094 [==============================] - 18s 17ms/step - loss: 0.0550\n",
            "Epoch 24/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0560\n",
            "Epoch 25/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0494\n",
            "Epoch 26/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0472\n",
            "Epoch 27/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.0460\n",
            "Epoch 28/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0458\n",
            "Epoch 29/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0446\n",
            "Epoch 30/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0398\n",
            "Epoch 31/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0404\n",
            "Epoch 32/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0393\n",
            "Epoch 33/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0389\n",
            "Epoch 34/200\n",
            "1094/1094 [==============================] - 18s 16ms/step - loss: 0.0360\n",
            "Epoch 35/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0351\n",
            "Epoch 36/200\n",
            "1094/1094 [==============================] - 18s 16ms/step - loss: 0.0338\n",
            "Epoch 37/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0351\n",
            "Epoch 38/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0364\n",
            "Epoch 39/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.0357\n",
            "Epoch 40/200\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 0.0312\n",
            "Epoch 41/200\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 0.0311\n",
            "Epoch 42/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0327\n",
            "Epoch 43/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0312\n",
            "Epoch 44/200\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 0.0349\n",
            "Epoch 45/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0291\n",
            "Epoch 46/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.0288\n",
            "Epoch 47/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0306\n",
            "Epoch 48/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0275\n",
            "Epoch 49/200\n",
            "1094/1094 [==============================] - 17s 15ms/step - loss: 0.0284\n",
            "Epoch 50/200\n",
            "1094/1094 [==============================] - 16s 14ms/step - loss: 0.0276\n",
            "Epoch 51/200\n",
            "1094/1094 [==============================] - 17s 16ms/step - loss: 0.0281\n",
            "Epoch 52/200\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0278\n",
            "Epoch 53/200\n",
            "1093/1094 [============================>.] - ETA: 0s - loss: 0.0276Restoring model weights from the end of the best epoch: 48.\n",
            "1094/1094 [==============================] - 16s 15ms/step - loss: 0.0276\n",
            "Epoch 53: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"sentence_completion_tf_model\")\n",
        "shutil.make_archive(\"sentence_completion_tf_model\", \"zip\", \"sentence_completion_tf_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OJPPHXn9HNHn",
        "outputId": "8789ccda-b160-4de9-a61a-7f90b450a9de"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sentence_completion_tf_model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "_qKN6YTyIg6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = ku.pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word.lower()\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "\n",
        "    return seed_text.title()"
      ],
      "metadata": {
        "id": "DVy_0FDw1kJn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"Hi\", 17 , model, max_seq_len))\n",
        "print(generate_text(\"Today I was going to\", 10, model, max_seq_len))\n",
        "print(generate_text(\"Now we shall head over to\", 20, model, max_seq_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1EjMUKlB_pB",
        "outputId": "14cfbb06-942b-4dad-ac18-a1a1406b342a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi Am Looking For Information Can You Help Me With A Place To Stay While Im In Town\n",
            "Today I Was Going To And A Table Day Day Bye That In Me Up\n",
            "Now We Shall Head Over To And From And What Time Will You Need The Taxi Taxi Food Type The Taxi The Of 4 For For\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AsX4blRqaRwx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4giGuM3D6ZHXRUpNba3ZZ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}